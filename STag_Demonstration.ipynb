{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STag Demonstration.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lDkywn1NeyV"
      },
      "source": [
        "# STag Demonstration\n",
        "\n",
        "The following iPython Jupyter notebook gives a step-by-step demonstration of how to use STag to get the tag probabilities and the predicted class for a spectra.\n",
        "\n",
        "# Setup\n",
        "\n",
        "The first step is to read in the beta values for each of the tags as well as an example spectrum (this can be modified to read in an appropriate spectrum of your choice)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "Ta4ahtHDK9DV",
        "outputId": "72ae8a41-2f2d-4a4f-f037-7758b52989fe"
      },
      "source": [
        "import beta_reader\n",
        "\n",
        "beta = beta_reader.beta_reader()\n",
        "spectra = np.load('/aty.npy')\n",
        "names = 'DES15C2aty'\n",
        "z = 0.149"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-16d15a67a308>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbeta_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/beta_reader.py\u001b[0m in \u001b[0;36mbeta_reader\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mFunction\u001b[0m \u001b[0mto\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \"\"\"\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mH_beta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Beta Values/h_beta_final2.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mSi_beta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Beta Values/si_beta_final2.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mHe_emi_beta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Beta Values/he_emi_beta_final2.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    533\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    534\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: /Beta Values/h_beta_final2.txt not found."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2UPzpBoQ2Jh"
      },
      "source": [
        "# Pre-processing\n",
        "\n",
        "In order to use STag, spectra need to be pre-processed appropriately. This involves filtering, de-redshifting, binning, continuum removal, apodisation, and scaling.\n",
        "\n",
        "All of these steps are handled by the spectra_preprocessing package, which largely uses methods made for the software [DASH](https://github.com/daniel-muthukrishna/astrodash)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQoFeWAvQ2bV"
      },
      "source": [
        "import spectra_preprocessing as sp\n",
        "\n",
        "#Read in the fits file of the spectra and extract the flux and wavelength\n",
        "fits_file = spectra\n",
        "table = fits.open(fits_file)\n",
        "flux = table[0].data\n",
        "w0 = table[0].header['CRVAL1']\n",
        "dw = table[0].header['CDELT1']\n",
        "p0 = table[0].header['CRPIX1']\n",
        "nlam = len(flux)\n",
        "wave = w0+dw*(np.arange(nlam, dtype='d')-p0)\n",
        "table.close()\n",
        "\n",
        "full = np.column_stack((wave, flux))\n",
        "\n",
        "#Initialise for pre-processing\n",
        "preProcess = sp.PreProcessing(full, 2500, 10000, 1024)\n",
        "\n",
        "#Do the pre-processing steps\n",
        "sfWave, sfFlux, minInd, maxInd, sfZ, sfArea = sp.preProcess.two_column_data(z, smooth=6, minWave=2500, maxWave=10000\n",
        "\n",
        "#Do scaling                                                                            \n",
        "flux_pro = sfFlux/sfArea                                                                           "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-sUbK8ZkgT2"
      },
      "source": [
        "# Cutting the Spectra\n",
        "\n",
        "Many of the tags use specific wavelength ranges of the spectrum rather than the whole thing and so we create multiple instances of the original spectrum cut at the corresponding wavelengths for each tag. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1EcHncfl0qO"
      },
      "source": [
        "cuts = np.genfromtxt('/a_and_b.txt', dtype=int)\n",
        "\n",
        "#Set wavelength indices\n",
        "si_cuts = cuts[0]\n",
        "he_cuts = cuts[1]\n",
        "ca_cuts = cuts[2]\n",
        "dp_cuts = cuts[3]\n",
        "fe_cuts = cuts[4]\n",
        "s_cuts = cuts[5]\n",
        "\n",
        "#Create the cut spectra for the relevant tags\n",
        "si_cut = flux_pro[:,Si_cuts[0]:Si_cuts[1]]\n",
        "he_cut = flux_pro[:,He_cuts[0]:He_cuts[1]]\n",
        "ca_cut = flux_pro[:,Ca_cuts[0]:Ca_cuts[1]]\n",
        "dp_cut = flux_pro[:,dp_cuts[0]:dp_cuts[1]]\n",
        "a5_cut = flux_pro[:,fe_cuts[0]:fe_cuts[1]]\n",
        "a56_cut = flux_pro[:,s_cuts[0]:s_cuts[1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buC5DrRJnuj4"
      },
      "source": [
        "# Tagging\n",
        "\n",
        "With spectra pre-processed and the necessary cuts made, we can now get the tag probabilities of the spectra and add them to an array ready to be given to the trained classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ilC7PlVoKtO"
      },
      "source": [
        "final = np.zeros([len(flux_pro),10])\n",
        "\n",
        "#Get Hydrogen tag probabilities\n",
        "H_result = log_reg_two(flux_pro, beta[0])\n",
        "final[:,0] = H_result\n",
        "\n",
        "#Get Silicon tag probabilities\n",
        "Si_result = log_reg_two(si_cut, beta[1])\n",
        "final[:,1] = Si_result\n",
        "\n",
        "#Get Helium emission tag probabilities\n",
        "He_emi_result = log_reg_two(he_cut, beta[2]\n",
        "\n",
        "#Get Helium p cygni tag probabilities\n",
        "He_cyg_result = log_reg_two(he_cut, beta[3])\n",
        "final[:,3] = He_cyg_result\n",
        "\n",
        "#Get Helium absorption tag probabilities\n",
        "He_abs_result = log_reg_two(he_cut, beta[4])\n",
        "final[:,4] = He_abs_result\n",
        "\n",
        "#Get Hydrogen alpha tag probabilities\n",
        "H_alp_result = log_reg_two(flux_pro, beta[5])\n",
        "final[:,5] = H_alp_result\n",
        "\n",
        "#Get Calcium tag probabilities\n",
        "Ca_result = log_reg_two(ca_cut, beta[6])\n",
        "final[:,6] = Ca_result\n",
        "\n",
        "#Get Helium double peak tag probabilities\n",
        "dp_result = log_reg_two(dp_cut, beta[7])\n",
        "final[:,7] = dp_result\n",
        "\n",
        "#Get Fe tag probabilities\n",
        "fe_result = log_reg_two(fe_cut, beta[8]\n",
        "final[:,8] = fe_result\n",
        "\n",
        "#Get S tag probabilities\n",
        "s_result = log_reg_two(s_cut, beta[9])\n",
        "final[:,9] = s_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0dH9swhqlFe"
      },
      "source": [
        "# Classifying\n",
        "\n",
        "We can now make our predictions for the class of the supernova by using the trained model. Since we are using softmax, we use 'np.argmax' to select the class with the highest probability, though one can see the probabilities of all the classes by printing 'class_prob'.\n",
        "\n",
        "The predicted class is given a number, which corresponds to one of the 5 possible classes:\n",
        "\n",
        "0 = Type Ia\n",
        "\n",
        "1 = Type II\n",
        "\n",
        "2 = Type Ib\n",
        "\n",
        "3 = Type Ic\n",
        "\n",
        "4 = Type IIb\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5vONcaOqjuY"
      },
      "source": [
        "#Load in the trained model\n",
        "model = keras.models.load_model('/Classifier_network2')\n",
        "\n",
        "#Make classification prediction\n",
        "class_prob = model.predict(final)\n",
        "preds = np.argmax(class_prob2, axis=-1)\n",
        "print(\"SN %s (with redshift %.3f) predicted class is %d with a %.3f probability \" %  (name,z,preds,class_prob[preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I3z-TRIlGUs"
      },
      "source": [
        "# Tag Probabilities\n",
        "\n",
        "One of the key features of STag is that all of the tags have probabilties, which can be accessed on demand."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOKy9yiflGnI"
      },
      "source": [
        "#Print the tag probabilities\n",
        "print(\"%s - H: %.2f, Si: %.2f, Ca: %.2f, Fe: %.2f, S: %.2f, He emi: %.2f, He cyg: %.2f, He abs: %.2f, Ha: %.2f, He DP: %.2f\" % (name,final[:,0],final[:,1],final[:,6],final[:,8],final[:,9],final[:,2],final[:,3],final[:,4],final[:,5],final[:,7]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vgy6qy7Zm461"
      },
      "source": [
        "# Closing Remarks\n",
        "\n",
        "One can use STag by following the steps outlined in this notebook, and with slight modifications one can adapt this code to run on multiple spectra rather than one at a time. \n",
        "\n",
        "Note that the classifying model used has only been trained on the 10 tags shown in this notebook, if one wishes to add additional tags then the model will need to be trained again. A more detailed description of how the tags have been made and how the model was built can be found in our paper: LINK GOES HERE."
      ]
    }
  ]
}