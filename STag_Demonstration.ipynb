{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lDkywn1NeyV"
   },
   "source": [
    "# STag Demonstration\n",
    "\n",
    "The following iPython Jupyter notebook gives a step-by-step demonstration of how to use STag to get the tag probabilities and the predicted class for a spectra.\n",
    "\n",
    "# Setup\n",
    "\n",
    "The first step is to read in the beta values for each of the tags as well as an example spectrum (this can be modified to read in an appropriate spectrum of your choice).\n",
    "\n",
    "**Note:** You will need to change the 'path' directory to the appropriate one for your own system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "Ta4ahtHDK9DV",
    "outputId": "72ae8a41-2f2d-4a4f-f037-7758b52989fe"
   },
   "outputs": [],
   "source": [
    "import beta_reader\n",
    "import numpy as np\n",
    "\n",
    "path = '/Users/willdavison/Downloads/STag-main'\n",
    "beta = beta_reader.beta_reader(path)\n",
    "spectra = '%s/DES15C2aty_C2_combined_150917_v03_b00.fits' % path\n",
    "name = 'DES15C2aty'\n",
    "z = 0.149"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2UPzpBoQ2Jh"
   },
   "source": [
    "# Pre-processing\n",
    "\n",
    "In order to use STag, spectra need to be pre-processed appropriately. This involves filtering, de-redshifting, binning, continuum removal, apodisation, and scaling.\n",
    "\n",
    "All of these steps are handled by the spectra_preprocessing package, which largely uses methods made for the software [DASH](https://github.com/daniel-muthukrishna/astrodash)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aQoFeWAvQ2bV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas module not installed. DASH will use numpy to load spectral files instead. This can be up to 10x slower.\n"
     ]
    }
   ],
   "source": [
    "import spectra_preprocessing as sp\n",
    "from astropy.io import fits\n",
    "\n",
    "#Read in the fits file of the spectra and extract the flux and wavelength\n",
    "fits_file = spectra\n",
    "table = fits.open(fits_file)\n",
    "flux = table[0].data\n",
    "w0 = table[0].header['CRVAL1']\n",
    "dw = table[0].header['CDELT1']\n",
    "p0 = table[0].header['CRPIX1']\n",
    "nlam = len(flux)\n",
    "wave = w0+dw*(np.arange(nlam, dtype='d')-p0)\n",
    "table.close()\n",
    "\n",
    "full = np.column_stack((wave, flux))\n",
    "\n",
    "#Initialise for pre-processing\n",
    "preProcess = sp.PreProcessing(full, 2500, 10000, 1024)\n",
    "\n",
    "#Do the pre-processing steps\n",
    "sfWave, sfFlux, minInd, maxInd, sfZ, sfArea = preProcess.two_column_data(z, smooth=6, minWave=2500, maxWave=10000)\n",
    "\n",
    "#Do scaling                                                                            \n",
    "flux_pro = sfFlux/sfArea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-sUbK8ZkgT2"
   },
   "source": [
    "# Cutting the Spectra\n",
    "\n",
    "Many of the tags use specific wavelength ranges of the spectrum rather than the whole thing and so we create multiple instances of the original spectrum cut at the corresponding wavelengths for each tag. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "N1EcHncfl0qO"
   },
   "outputs": [],
   "source": [
    "cuts = np.genfromtxt('%s/cuts.txt' % path, dtype=int)\n",
    "\n",
    "#Set wavelength indices\n",
    "si_cuts = cuts[0]\n",
    "he_cuts = cuts[1]\n",
    "ca_cuts = cuts[2]\n",
    "dp_cuts = cuts[3]\n",
    "fe_cuts = cuts[4]\n",
    "s_cuts = cuts[5]\n",
    "\n",
    "#Create the cut spectra for the relevant tags\n",
    "si_cut = flux_pro[si_cuts[0]:si_cuts[1]]\n",
    "he_cut = flux_pro[he_cuts[0]:he_cuts[1]]\n",
    "ca_cut = flux_pro[ca_cuts[0]:ca_cuts[1]]\n",
    "dp_cut = flux_pro[dp_cuts[0]:dp_cuts[1]]\n",
    "fe_cut = flux_pro[fe_cuts[0]:fe_cuts[1]]\n",
    "s_cut = flux_pro[s_cuts[0]:s_cuts[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buC5DrRJnuj4"
   },
   "source": [
    "# Tagging\n",
    "\n",
    "With spectra pre-processed and the necessary cuts made, we can now get the tag probabilities of the spectra and add them to an array ready to be given to the trained classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-ilC7PlVoKtO"
   },
   "outputs": [],
   "source": [
    "from tagging import log_reg_two\n",
    "\n",
    "final = np.zeros([1,10])\n",
    "\n",
    "#Get Hydrogen tag probabilities\n",
    "H_result = log_reg_two(flux_pro, beta[0])\n",
    "final[0][0] = H_result\n",
    "\n",
    "#Get Silicon tag probabilities\n",
    "Si_result = log_reg_two(si_cut, beta[1])\n",
    "final[0][1] = Si_result\n",
    "\n",
    "#Get Helium emission tag probabilities\n",
    "He_emi_result = log_reg_two(he_cut, beta[2])\n",
    "final[0][2] = He_emi_result\n",
    "\n",
    "#Get Helium p cygni tag probabilities\n",
    "He_cyg_result = log_reg_two(he_cut, beta[3])\n",
    "final[0][3] = He_cyg_result\n",
    "\n",
    "#Get Helium absorption tag probabilities\n",
    "He_abs_result = log_reg_two(he_cut, beta[4])\n",
    "final[0][4] = He_abs_result\n",
    "\n",
    "#Get Hydrogen alpha tag probabilities\n",
    "H_alp_result = log_reg_two(flux_pro, beta[5])\n",
    "final[0][5] = H_alp_result\n",
    "\n",
    "#Get Calcium tag probabilities\n",
    "Ca_result = log_reg_two(ca_cut, beta[6])\n",
    "final[0][6] = Ca_result\n",
    "\n",
    "#Get Helium double peak tag probabilities\n",
    "dp_result = log_reg_two(dp_cut, beta[7])\n",
    "final[0][7] = dp_result\n",
    "\n",
    "#Get Fe tag probabilities\n",
    "fe_result = log_reg_two(fe_cut, beta[8])\n",
    "final[0][8] = fe_result\n",
    "\n",
    "#Get S tag probabilities\n",
    "s_result = log_reg_two(s_cut, beta[9])\n",
    "final[0][9] = s_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0dH9swhqlFe"
   },
   "source": [
    "# Classifying\n",
    "\n",
    "We can now make our predictions for the class of the supernova by using the trained model. Since we are using softmax, we use 'np.argmax' to select the class with the highest probability, though one can see the probabilities of all the classes by printing 'class_prob'.\n",
    "\n",
    "The predicted class is given a number, which corresponds to one of the 5 possible classes:\n",
    "\n",
    "0 = Type Ia\n",
    "\n",
    "1 = Type II\n",
    "\n",
    "2 = Type Ib\n",
    "\n",
    "3 = Type Ic\n",
    "\n",
    "4 = Type IIb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "v5vONcaOqjuY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SN DES15C2aty (with redshift 0.149) predicted class is 0 with a 0.986 probability \n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "#Load in the trained model\n",
    "model = keras.models.load_model('%s/Classifier Model' % path)\n",
    "\n",
    "#Make classification prediction\n",
    "class_prob = model.predict(final)\n",
    "preds = np.argmax(class_prob, axis=-1)\n",
    "print(\"SN %s (with redshift %.3f) predicted class is %d with a %.3f probability \" %  (name,z,preds,class_prob[0][preds]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5I3z-TRIlGUs"
   },
   "source": [
    "# Tag Probabilities\n",
    "\n",
    "One of the key features of STag is that all of the tags have probabilties, which can be accessed on demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zOKy9yiflGnI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DES15C2aty - H: 0.00, Si: 1.00, Ca: 1.00, Fe: 1.00, S: 0.00, He emi: 0.00, He cyg: 0.00, He abs: 0.00, Ha: 0.01, He DP: 0.04\n"
     ]
    }
   ],
   "source": [
    "#Print the tag probabilities\n",
    "print(\"%s - H: %.2f, Si: %.2f, Ca: %.2f, Fe: %.2f, S: %.2f, He emi: %.2f, He cyg: %.2f, He abs: %.2f, Ha: %.2f, He DP: %.2f\" % (name,final[0][0],final[0][1],final[0][6],final[0][8],final[0][9],final[0][2],final[0][3],final[0][4],final[0][5],final[0][7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vgy6qy7Zm461"
   },
   "source": [
    "# Closing Remarks\n",
    "\n",
    "One can use STag by following the steps outlined in this notebook, and with slight modifications one can adapt this code to run on multiple spectra rather than one at a time. \n",
    "\n",
    "Note that the classifying model used has only been trained on the 10 tags shown in this notebook, if one wishes to add additional tags then the model will need to be trained again. A more detailed description of how the tags have been made and how the model was built can be found in our paper: LINK GOES HERE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "STag Demonstration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
